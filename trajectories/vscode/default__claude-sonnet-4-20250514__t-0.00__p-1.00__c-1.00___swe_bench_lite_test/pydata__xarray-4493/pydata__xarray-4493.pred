{"model_name_or_path": "default__claude-sonnet-4-20250514__t-0.00__p-1.00__c-1.00___swe_bench_lite_test", "instance_id": "pydata__xarray-4493", "model_patch": "diff --git a/reproduce_issue.py b/reproduce_issue.py\nnew file mode 100644\nindex 00000000..50d55ff6\n--- /dev/null\n+++ b/reproduce_issue.py\n@@ -0,0 +1,41 @@\n+#!/usr/bin/env python3\n+\n+import numpy as np\n+import xarray as xr\n+import dask.array as da\n+\n+print(\"Testing DataSet.update issue with chunked dask DataArray...\")\n+\n+# Test case 1: From the PR description\n+print(\"\\n=== Test case 1: DataSet.update issue ===\")\n+foo = xr.DataArray(np.random.randn(3, 3), dims=(\"x\", \"y\")).chunk()  # foo is chunked\n+print(f\"foo is chunked: {hasattr(foo.data, 'chunks')}\")\n+print(f\"foo data type: {type(foo.data)}\")\n+\n+ds = xr.Dataset({\"foo\": foo, \"bar\": (\"x\", [1, 2, 3])})  # foo is still chunked here\n+print(f\"ds.foo is chunked: {hasattr(ds.foo.data, 'chunks')}\")\n+print(f\"ds.foo data type: {type(ds.foo.data)}\")\n+\n+update_dict = {\"foo\": ((\"x\", \"y\"), ds.foo[1:, :]), \"bar\": (\"x\", ds.bar[1:])}\n+print(f\"update_dict['foo'][1] is chunked: {hasattr(update_dict['foo'][1].data, 'chunks')}\")\n+print(f\"update_dict['foo'][1] data type: {type(update_dict['foo'][1].data)}\")\n+\n+ds.update(update_dict)\n+print(f\"After update - ds.foo is chunked: {hasattr(ds.foo.data, 'chunks')}\")\n+print(f\"After update - ds.foo data type: {type(ds.foo.data)}\")\n+\n+# Test case 2: Dataset constructor issue\n+print(\"\\n=== Test case 2: Dataset constructor issue ===\")\n+x = da.random.randint(1, 10, size=(100, 25))\n+print(f\"Original dask array type: {type(x)}\")\n+\n+ds1 = xr.Dataset(dict(a=xr.DataArray(x, dims=('x', 'y'))))\n+print(f\"ds1.a data type: {type(ds1.a.data)}\")\n+print(f\"ds1.a is chunked: {hasattr(ds1.a.data, 'chunks')}\")\n+\n+# Recreate the dataset with the same array, but also redefine the dimensions\n+ds2 = xr.Dataset(dict(a=(('x', 'y'), ds1.a)))\n+print(f\"ds2.a data type: {type(ds2.a.data)}\")\n+print(f\"ds2.a is chunked: {hasattr(ds2.a.data, 'chunks')}\")\n+\n+print(\"\\nDone!\")\n\\ No newline at end of file\ndiff --git a/test_comprehensive.py b/test_comprehensive.py\nnew file mode 100644\nindex 00000000..87e353ef\n--- /dev/null\n+++ b/test_comprehensive.py\n@@ -0,0 +1,125 @@\n+#!/usr/bin/env python3\n+\n+import numpy as np\n+import xarray as xr\n+import dask.array as da\n+\n+def test_dataset_update_preserves_dask():\n+    \"\"\"Test that Dataset.update preserves dask arrays.\"\"\"\n+    print(\"Testing Dataset.update with dask arrays...\")\n+    \n+    # Create a chunked dask DataArray\n+    foo = xr.DataArray(np.random.randn(3, 3), dims=(\"x\", \"y\")).chunk()\n+    ds = xr.Dataset({\"foo\": foo, \"bar\": (\"x\", [1, 2, 3])})\n+    \n+    # Verify initial state\n+    assert hasattr(ds.foo.data, 'chunks'), \"Initial foo should be chunked\"\n+    \n+    # Update with a sliced dask array\n+    update_dict = {\"foo\": ((\"x\", \"y\"), ds.foo[1:, :]), \"bar\": (\"x\", ds.bar[1:])}\n+    \n+    # Verify the update data is still chunked\n+    assert hasattr(update_dict[\"foo\"][1].data, 'chunks'), \"Update data should be chunked\"\n+    \n+    # Perform the update\n+    ds.update(update_dict)\n+    \n+    # Verify the result is still chunked\n+    assert hasattr(ds.foo.data, 'chunks'), \"Updated foo should still be chunked\"\n+    print(\"\u2713 Dataset.update preserves dask arrays\")\n+\n+\n+def test_dataset_constructor_preserves_dask():\n+    \"\"\"Test that Dataset constructor preserves dask arrays.\"\"\"\n+    print(\"Testing Dataset constructor with dask arrays...\")\n+    \n+    # Create a dask array\n+    x = da.random.randint(1, 10, size=(100, 25))\n+    \n+    # Create dataset with DataArray\n+    ds1 = xr.Dataset(dict(a=xr.DataArray(x, dims=('x', 'y'))))\n+    assert hasattr(ds1.a.data, 'chunks'), \"ds1.a should be chunked\"\n+    \n+    # Recreate dataset with tuple format (this was the problematic case)\n+    ds2 = xr.Dataset(dict(a=(('x', 'y'), ds1.a)))\n+    assert hasattr(ds2.a.data, 'chunks'), \"ds2.a should still be chunked\"\n+    print(\"\u2713 Dataset constructor preserves dask arrays\")\n+\n+\n+def test_variable_creation_preserves_dask():\n+    \"\"\"Test that Variable creation preserves dask arrays.\"\"\"\n+    print(\"Testing Variable creation with dask arrays...\")\n+    \n+    # Create a dask DataArray\n+    dask_data = da.random.random((10, 5))\n+    da_array = xr.DataArray(dask_data, dims=('x', 'y'))\n+    \n+    # Create Variable from DataArray (this should preserve dask)\n+    from xarray.core.variable import as_variable\n+    var = as_variable(da_array)\n+    assert hasattr(var.data, 'chunks'), \"Variable should preserve dask array\"\n+    \n+    # Create Variable from tuple with DataArray (this was problematic)\n+    var2 = as_variable((('x', 'y'), da_array))\n+    assert hasattr(var2.data, 'chunks'), \"Variable from tuple should preserve dask array\"\n+    print(\"\u2713 Variable creation preserves dask arrays\")\n+\n+\n+def test_as_compatible_data_preserves_dask():\n+    \"\"\"Test that as_compatible_data preserves dask arrays.\"\"\"\n+    print(\"Testing as_compatible_data with dask arrays...\")\n+    \n+    from xarray.core.variable import as_compatible_data\n+    \n+    # Test with raw dask array\n+    dask_data = da.random.random((10, 5))\n+    result = as_compatible_data(dask_data)\n+    assert hasattr(result, 'chunks'), \"Raw dask array should be preserved\"\n+    \n+    # Test with DataArray containing dask array\n+    da_array = xr.DataArray(dask_data, dims=('x', 'y'))\n+    result2 = as_compatible_data(da_array)\n+    assert hasattr(result2, 'chunks'), \"DataArray with dask should be preserved\"\n+    \n+    # Test with Variable containing dask array\n+    from xarray.core.variable import Variable\n+    var = Variable(('x', 'y'), dask_data)\n+    result3 = as_compatible_data(var)\n+    assert hasattr(result3, 'chunks'), \"Variable with dask should be preserved\"\n+    print(\"\u2713 as_compatible_data preserves dask arrays\")\n+\n+\n+def test_edge_cases():\n+    \"\"\"Test edge cases to ensure robustness.\"\"\"\n+    print(\"Testing edge cases...\")\n+    \n+    # Test with numpy array (should still work)\n+    numpy_data = np.random.random((10, 5))\n+    da_array = xr.DataArray(numpy_data, dims=('x', 'y'))\n+    ds = xr.Dataset(dict(a=(('x', 'y'), da_array)))\n+    assert isinstance(ds.a.data, np.ndarray), \"Numpy arrays should remain numpy arrays\"\n+    \n+    # Test with mixed dask and numpy\n+    dask_data = da.random.random((10, 5))\n+    dask_array = xr.DataArray(dask_data, dims=('x', 'y'))\n+    numpy_array = xr.DataArray(numpy_data, dims=('x', 'y'))\n+    \n+    ds = xr.Dataset({'dask_var': dask_array, 'numpy_var': numpy_array})\n+    update_dict = {\n+        'dask_var': (('x', 'y'), dask_array[1:, :]),\n+        'numpy_var': (('x', 'y'), numpy_array[1:, :])\n+    }\n+    ds.update(update_dict)\n+    \n+    assert hasattr(ds.dask_var.data, 'chunks'), \"Dask variable should remain chunked\"\n+    assert isinstance(ds.numpy_var.data, np.ndarray), \"Numpy variable should remain numpy\"\n+    print(\"\u2713 Edge cases handled correctly\")\n+\n+\n+if __name__ == \"__main__\":\n+    test_dataset_update_preserves_dask()\n+    test_dataset_constructor_preserves_dask()\n+    test_variable_creation_preserves_dask()\n+    test_as_compatible_data_preserves_dask()\n+    test_edge_cases()\n+    print(\"\\nAll tests passed! \ud83c\udf89\")\n\\ No newline at end of file\ndiff --git a/test_dask_preservation.py b/test_dask_preservation.py\nnew file mode 100644\nindex 00000000..beedbbec\n--- /dev/null\n+++ b/test_dask_preservation.py\n@@ -0,0 +1,96 @@\n+#!/usr/bin/env python3\n+\"\"\"\n+Test to ensure dask arrays are preserved in Dataset operations.\n+This test can be added to the xarray test suite to prevent regression.\n+\"\"\"\n+\n+import numpy as np\n+import pytest\n+\n+import xarray as xr\n+from xarray.core.pycompat import dask_array_type\n+\n+da = pytest.importorskip(\"dask.array\")\n+\n+\n+class TestDaskPreservation:\n+    \"\"\"Test that dask arrays are preserved in various Dataset operations.\"\"\"\n+\n+    def test_dataset_update_preserves_dask(self):\n+        \"\"\"Test that Dataset.update preserves dask arrays (GH issue).\"\"\"\n+        # Create a chunked dask DataArray\n+        foo = xr.DataArray(np.random.randn(3, 3), dims=(\"x\", \"y\")).chunk()\n+        ds = xr.Dataset({\"foo\": foo, \"bar\": (\"x\", [1, 2, 3])})\n+        \n+        # Verify initial state\n+        assert isinstance(ds.foo.data, dask_array_type)\n+        \n+        # Update with a sliced dask array\n+        update_dict = {\"foo\": ((\"x\", \"y\"), ds.foo[1:, :]), \"bar\": (\"x\", ds.bar[1:])}\n+        \n+        # Verify the update data is still chunked\n+        assert isinstance(update_dict[\"foo\"][1].data, dask_array_type)\n+        \n+        # Perform the update\n+        ds.update(update_dict)\n+        \n+        # Verify the result is still chunked\n+        assert isinstance(ds.foo.data, dask_array_type)\n+\n+    def test_dataset_constructor_preserves_dask(self):\n+        \"\"\"Test that Dataset constructor preserves dask arrays (GH issue).\"\"\"\n+        # Create a dask array\n+        x = da.random.randint(1, 10, size=(100, 25))\n+        \n+        # Create dataset with DataArray\n+        ds1 = xr.Dataset(dict(a=xr.DataArray(x, dims=('x', 'y'))))\n+        assert isinstance(ds1.a.data, dask_array_type)\n+        \n+        # Recreate dataset with tuple format (this was the problematic case)\n+        ds2 = xr.Dataset(dict(a=(('x', 'y'), ds1.a)))\n+        assert isinstance(ds2.a.data, dask_array_type)\n+\n+    def test_as_compatible_data_preserves_dask_dataarray(self):\n+        \"\"\"Test that as_compatible_data preserves dask arrays in DataArrays.\"\"\"\n+        from xarray.core.variable import as_compatible_data\n+        \n+        # Create a dask DataArray\n+        dask_data = da.random.random((10, 5))\n+        da_array = xr.DataArray(dask_data, dims=('x', 'y'))\n+        \n+        # Test as_compatible_data preserves dask\n+        result = as_compatible_data(da_array)\n+        assert isinstance(result, dask_array_type)\n+\n+    def test_mixed_dask_numpy_preservation(self):\n+        \"\"\"Test that mixed dask and numpy arrays are handled correctly.\"\"\"\n+        # Create mixed data\n+        dask_data = da.random.random((10, 5))\n+        numpy_data = np.random.random((10, 5))\n+        \n+        dask_array = xr.DataArray(dask_data, dims=('x', 'y'))\n+        numpy_array = xr.DataArray(numpy_data, dims=('x', 'y'))\n+        \n+        # Test in Dataset constructor\n+        ds = xr.Dataset({'dask_var': dask_array, 'numpy_var': numpy_array})\n+        assert isinstance(ds.dask_var.data, dask_array_type)\n+        assert isinstance(ds.numpy_var.data, np.ndarray)\n+        \n+        # Test in update\n+        update_dict = {\n+            'dask_var': (('x', 'y'), dask_array[1:, :]),\n+            'numpy_var': (('x', 'y'), numpy_array[1:, :])\n+        }\n+        ds.update(update_dict)\n+        \n+        assert isinstance(ds.dask_var.data, dask_array_type)\n+        assert isinstance(ds.numpy_var.data, np.ndarray)\n+\n+\n+if __name__ == \"__main__\":\n+    test = TestDaskPreservation()\n+    test.test_dataset_update_preserves_dask()\n+    test.test_dataset_constructor_preserves_dask()\n+    test.test_as_compatible_data_preserves_dask_dataarray()\n+    test.test_mixed_dask_numpy_preservation()\n+    print(\"All dask preservation tests passed!\")\n\\ No newline at end of file\ndiff --git a/test_edge_cases.py b/test_edge_cases.py\nnew file mode 100644\nindex 00000000..40143324\n--- /dev/null\n+++ b/test_edge_cases.py\n@@ -0,0 +1,110 @@\n+#!/usr/bin/env python3\n+\n+import numpy as np\n+import xarray as xr\n+import dask.array as da\n+\n+def test_circular_import():\n+    \"\"\"Test that our fix doesn't cause circular import issues.\"\"\"\n+    print(\"Testing circular import...\")\n+    \n+    # This should work without issues\n+    from xarray.core.variable import as_compatible_data\n+    from xarray.core.dataarray import DataArray\n+    \n+    # Create a DataArray and test as_compatible_data\n+    data = np.random.random((5, 5))\n+    da_array = DataArray(data, dims=('x', 'y'))\n+    result = as_compatible_data(da_array)\n+    \n+    assert isinstance(result, np.ndarray), \"Should return numpy array for numpy data\"\n+    print(\"\u2713 No circular import issues\")\n+\n+\n+def test_dataarray_with_coords():\n+    \"\"\"Test DataArrays with coordinates.\"\"\"\n+    print(\"Testing DataArrays with coordinates...\")\n+    \n+    # Create a DataArray with coordinates\n+    data = da.random.random((5, 5))\n+    coords = {'x': range(5), 'y': range(5)}\n+    da_array = xr.DataArray(data, dims=('x', 'y'), coords=coords)\n+    \n+    # Test in Dataset constructor\n+    ds = xr.Dataset({'var': (('x', 'y'), da_array)})\n+    assert hasattr(ds['var'].data, 'chunks'), \"Should preserve dask array with coords\"\n+    \n+    # Test in update\n+    ds2 = xr.Dataset({'other': (('x',), np.arange(5))})\n+    ds2.update({'var': (('x', 'y'), da_array)})\n+    assert hasattr(ds2['var'].data, 'chunks'), \"Should preserve dask array in update with coords\"\n+    print(\"\u2713 DataArrays with coordinates work correctly\")\n+\n+\n+def test_different_dask_array_types():\n+    \"\"\"Test different types of dask arrays.\"\"\"\n+    print(\"Testing different dask array types...\")\n+    \n+    # Test different dtypes\n+    int_data = da.random.randint(0, 10, size=(5, 5))\n+    float_data = da.random.random((5, 5))\n+    \n+    int_da = xr.DataArray(int_data, dims=('x', 'y'))\n+    float_da = xr.DataArray(float_data, dims=('x', 'y'))\n+    \n+    ds = xr.Dataset({\n+        'int_var': (('x', 'y'), int_da),\n+        'float_var': (('x', 'y'), float_da)\n+    })\n+    \n+    assert hasattr(ds['int_var'].data, 'chunks'), \"Int dask array should be preserved\"\n+    assert hasattr(ds['float_var'].data, 'chunks'), \"Float dask array should be preserved\"\n+    assert 'int' in str(ds['int_var'].dtype), \"Int dtype should be preserved\"\n+    assert 'float' in str(ds['float_var'].dtype), \"Float dtype should be preserved\"\n+    print(\"\u2713 Different dask array types work correctly\")\n+\n+\n+def test_nested_structures():\n+    \"\"\"Test nested data structures.\"\"\"\n+    print(\"Testing nested structures...\")\n+    \n+    # Test with nested tuples (should still work)\n+    data = da.random.random((3, 3))\n+    da_array = xr.DataArray(data, dims=('x', 'y'))\n+    \n+    # This should work (tuple with DataArray)\n+    from xarray.core.variable import as_compatible_data\n+    result = as_compatible_data(da_array)\n+    assert hasattr(result, 'chunks'), \"Nested DataArray should preserve dask\"\n+    print(\"\u2713 Nested structures work correctly\")\n+\n+\n+def test_performance():\n+    \"\"\"Test that our fix doesn't significantly impact performance.\"\"\"\n+    print(\"Testing performance...\")\n+    \n+    import time\n+    \n+    # Create a large dask array\n+    large_data = da.random.random((1000, 1000), chunks=(100, 100))\n+    da_array = xr.DataArray(large_data, dims=('x', 'y'))\n+    \n+    # Time the Dataset creation (should be fast, no computation)\n+    start_time = time.time()\n+    ds = xr.Dataset({'var': (('x', 'y'), da_array)})\n+    end_time = time.time()\n+    \n+    # Should be very fast (< 1 second) since no computation should occur\n+    elapsed = end_time - start_time\n+    assert elapsed < 1.0, f\"Dataset creation took too long: {elapsed:.3f}s\"\n+    assert hasattr(ds['var'].data, 'chunks'), \"Large dask array should be preserved\"\n+    print(f\"\u2713 Performance test passed ({elapsed:.3f}s)\")\n+\n+\n+if __name__ == \"__main__\":\n+    test_circular_import()\n+    test_dataarray_with_coords()\n+    test_different_dask_array_types()\n+    test_nested_structures()\n+    test_performance()\n+    print(\"\\nAll edge case tests passed! \ud83c\udf89\")\n\\ No newline at end of file\ndiff --git a/xarray/core/variable.py b/xarray/core/variable.py\nindex 64c1895d..1e74b783 100644\n--- a/xarray/core/variable.py\n+++ b/xarray/core/variable.py\n@@ -204,6 +204,11 @@ def as_compatible_data(data, fastpath=False):\n     if isinstance(data, Variable):\n         return data.data\n \n+    # Handle DataArray by extracting its variable's data to preserve dask arrays\n+    from .dataarray import DataArray\n+    if isinstance(data, DataArray):\n+        return data.variable.data\n+\n     if isinstance(data, NON_NUMPY_SUPPORTED_ARRAY_TYPES):\n         return _maybe_wrap_data(data)\n \n"}